{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of emails using Shorttext library\n",
    "\n",
    "This notebook will test the different classification methods offered by the Shorttext library.\n",
    "\n",
    "---\n",
    "__Organization:__\n",
    "1. Put the csv file in the right format for shorttext model and split the data between train and test\n",
    "2. Preprocess the text\n",
    "3. Train a LDA model and make classification using topics found\n",
    "4. Use a Word2Vec representation of words and make classification\n",
    "\n",
    "__What is left to be done:__\n",
    "1. Put the csv file in the right format for shorttext model and split the data between train and test<br>\n",
    "-- Change \"Fatou_relabeled\" by the final dataframe\n",
    "\n",
    "2. Preprocess the text<br>\n",
    "-- Try stemming\n",
    "\n",
    "3. Train a LDA model and make classification using topics found<br>\n",
    "3.1. Train a LDA model and make classification using topics found<br>\n",
    "---- Choose the right number of topics (try different values for k and keep the value that gives the highest cross-validation score (http://scikit-learn.org/stable/modules/cross_validation.html)<br>\n",
    "3.3. Classify using Scikit-Learn Classifiers<br>\n",
    "---- Try different SKLearn classifiers (GaussianNB, GradientBoostingClassifier, etc..)<br>\n",
    "---- Optimize parameters for classifiers (for example for RandomForestClassifier, change number of trees)\n",
    "\n",
    "4. Use a Word2Vec representation of words and make classification<br>\n",
    "4.3. Classify using a Convolutional Neural Network\n",
    "---- Optimize parameters for the CNN (number of epochs, size, etc...) => check Shorttext github<br>\n",
    "---- Try a double CNN<br>\n",
    "\n",
    "4.4. Classify using a C-LSTM Neural Network<br>\n",
    "---- Optimize parameters for the C-LSTM (number of epochs, size, etc...) => check Shorttext github<br>\n",
    "\n",
    "- <strong>What can be tested also:</strong> \n",
    "- Try metrics different than accuracy like f1-score, precision, etc.\n",
    "- Make a comparison of all methods\n",
    "- Add useful graphs\n",
    "\n",
    "__Keep in mind:__\n",
    "\n",
    "Unfortunately, it only works with Python 2. You can create a Python 2 environment using conda <br>see here => https://conda.io/docs/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U shorttext\n",
    "#!pip install -U spacy\n",
    "#!spacy download en\n",
    "import pandas as pd\n",
    "import operator\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import shorttext\n",
    "from shorttext.utils import text_preprocessor\n",
    "from shorttext.utils import load_word2vec_model\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def predict(classifier, mail):\n",
    "    #function that takes a message and a shorttext classifer then predict the category associated\n",
    "    probas = classifier.score(mail)\n",
    "    category = max(probas.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    return(category)\n",
    "\n",
    "\n",
    "def create_df_from_dict(dictionary, categories):\n",
    "    #create a dataframe with columns \"Label\" and \"Message\" from the shorttext dictionary\n",
    "    df = pd.DataFrame()\n",
    "    for cat in categories :\n",
    "        class_size = len(dictionary[cat])\n",
    "        labels = pd.Series([cat]*class_size)\n",
    "        messages = pd.Series(dictionary[cat])\n",
    "        tmp = pd.concat([pd.DataFrame(labels),pd.Series(messages)],axis=1)\n",
    "        tmp.columns = [\"Label\", \"Message\"]\n",
    "        df = pd.concat([df,tmp],axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Put the csv file in the right format for shorttext model and split the data between train and test\n",
    "\n",
    "The file has to obey these rules:\n",
    "\n",
    "- there is a heading; and\n",
    "- there are at least two columns: first the labels, and second the short text under the labels (everything being the second column will be neglected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/recombined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we add the catgegories names\n",
    "categories = [\"miscl.\", \"conflicts\", \"attendance\", \"assignments\", \"enrollment\", \"internal\", \"dsp\", \"regrades\"]\n",
    "df[\"Label\"] = df.Category.apply(lambda cat : categories[cat-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenate the body and the subject\n",
    "df[\"Message\"] = df[\"Subject\"] + \" \" + df[\"Body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data between train and test\n",
    "def stratified_train_test_split(X, y, test_size, seed):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train.shape', (1064,))\n",
      "('X_test.shape', (456,))\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = stratified_train_test_split(df[\"Message\"], df[\"Label\"], test_size, seed)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes proportions in train set\n",
      "miscl.         0.379699\n",
      "assignments    0.212406\n",
      "conflicts      0.132519\n",
      "enrollment     0.106203\n",
      "dsp            0.069549\n",
      "attendance     0.047932\n",
      "internal       0.033835\n",
      "regrades       0.017857\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "Classes proportions in test set\n",
      "miscl.         0.379386\n",
      "assignments    0.212719\n",
      "conflicts      0.131579\n",
      "enrollment     0.105263\n",
      "dsp            0.070175\n",
      "attendance     0.048246\n",
      "internal       0.032895\n",
      "regrades       0.019737\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes proportions in train set\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\")\n",
    "print(\"Classes proportions in test set\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>assignments</td>\n",
       "      <td>Re: HW2 forgot to attach screenshot of IPython...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>assignments</td>\n",
       "      <td>Re: Self-Grade hw 8 turned in at 12:02 am grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>dsp</td>\n",
       "      <td>Re: DSP thanks for your email! please let me k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>assignments</td>\n",
       "      <td>Re:  iPython Submission hi jodie,  unfortunate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>assignments</td>\n",
       "      <td>Minutes Late HW hello ms. li,       yesterday,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label                                            Message\n",
       "710   assignments  Re: HW2 forgot to attach screenshot of IPython...\n",
       "1192  assignments  Re: Self-Grade hw 8 turned in at 12:02 am grad...\n",
       "418           dsp  Re: DSP thanks for your email! please let me k...\n",
       "647   assignments  Re:  iPython Submission hi jodie,  unfortunate...\n",
       "668   assignments  Minutes Late HW hello ms. li,       yesterday,..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final training dataframe\n",
    "train = pd.concat([y_train, X_train],axis=1)\n",
    "train.columns = [\"Label\", \"Message\"]\n",
    "train.to_csv(\"../data/train_set_in_shorttext_format.csv\", index=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>enrollment</td>\n",
       "      <td>Re: Graduating Senior: Enrollment from Waitlis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>miscl.</td>\n",
       "      <td>Lab 109 GSI email? hi,  i am an eecs 47d stude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>attendance</td>\n",
       "      <td>Re: Lab excuse hi sarah,  we have buffer weeks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>assignments</td>\n",
       "      <td>Re: Uploading Homework problem hi youdong,  i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>miscl.</td>\n",
       "      <td>Re: EE  Final Exam , thank you so much this wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label                                            Message\n",
       "156   enrollment  Re: Graduating Senior: Enrollment from Waitlis...\n",
       "950       miscl.  Lab 109 GSI email? hi,  i am an eecs 47d stude...\n",
       "685   attendance  Re: Lab excuse hi sarah,  we have buffer weeks...\n",
       "788  assignments  Re: Uploading Homework problem hi youdong,  i ...\n",
       "484       miscl.  Re: EE  Final Exam , thank you so much this wo..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final test dataframe\n",
    "test = pd.concat([y_test, X_test],axis=1)\n",
    "test.columns = [\"Label\", \"Message\"]\n",
    "test.to_csv(\"../data/test_set_in_shorttext_format.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess the text\n",
    "\n",
    "- remove punctuation\n",
    "- lemmatize words\n",
    "- put to lower cases\n",
    "- remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionary where key = \"category\" and value = list of emails in that category\n",
    "trainclassdict = shorttext.data.retrieve_csvdata_as_dict('../data/train_set_in_shorttext_format.csv')\n",
    "testclassdict = shorttext.data.retrieve_csvdata_as_dict('../data/test_set_in_shorttext_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#preprocessing functions\n",
    "step1fcn = lambda s: re.sub(\"[^a-zA-Z]\", \" \", s)\n",
    "step2fcn = lambda s: ' '.join(map(lambda word: lemmatizer.lemmatize(word), s.split(' ')))\n",
    "step3fcn = lambda s: s.lower()\n",
    "step4fcn = lambda s: re.sub(' +',' ',\" \".join([word for word in s.split(\" \") if not word in eng_stopwords]))\n",
    "\n",
    "#pipeline\n",
    "pipeline = [step1fcn, step2fcn, step3fcn, step4fcn]\n",
    "preprocessor = text_preprocessor(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' maryland blue crab annapolis dog '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"  Maryland blue had crab in, having Annapolis dogs!\"\n",
    "preprocessor(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of cleaning\n",
    "cat = \"conflicts\"\n",
    "#print(\"Before : {}\".format(trainclassdict[cat][0]))\n",
    "#print(\"\")\n",
    "#print(\"After: {}\".format(preprocessor(trainclassdict[cat][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean the train data\n",
    "for cat in categories :\n",
    "    class_size = len(trainclassdict[cat])\n",
    "    for i in range(class_size):\n",
    "        trainclassdict[cat][i] = preprocessor(trainclassdict[cat][i])\n",
    "\n",
    "#clean the test data       \n",
    "for cat in categories :\n",
    "    class_size = len(testclassdict[cat])\n",
    "    for i in range(class_size):\n",
    "        testclassdict[cat][i] = preprocessor(testclassdict[cat][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dataframe for train and test\n",
    "train = create_df_from_dict(trainclassdict, categories)\n",
    "test = create_df_from_dict(testclassdict, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classify with LDA model \n",
    "\n",
    "- We train a LDA model with k number of topics (k can be determined by cross-validation)\n",
    "- The LDA model converts every text to a vector\n",
    "- The cos classifier compute the cosinus between the vector representing the text and the vector representing the label\n",
    "- The sklearn classifer uses the coefficients of the vector as features\n",
    "\n",
    "__Reference__: http://shorttext.readthedocs.io/en/latest/tutorial_topic.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Train the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "topicmodeler = shorttext.generators.LDAModeler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics = 7\n",
    "topicmodeler.train(trainclassdict, num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = 'exam conflict hi based school policy offering additional accommodation option involved club sport conflict exam time staff member time midterm exam may proctored staff member supervising let know would like take accommodation thanks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05767095,  0.33613182,  0.93294021,  0.05779112,  0.057672  ,\n",
       "        0.05764608,  0.05764608])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topic vector representation\n",
    "topicmodeler.retrieve_topicvec(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Classify using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_classifier = shorttext.classifiers.TopicVectorCosineDistanceClassifier(topicmodeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assignments': 0.88386267,\n",
       " 'attendance': 0.44776478,\n",
       " 'conflicts': 0.88386267,\n",
       " 'dsp': 0.47317448,\n",
       " 'enrollment': 0.88386267,\n",
       " 'internal': 0.46643716,\n",
       " 'miscl.': 0.74053299,\n",
       " 'regrades': 0.46540907}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions\n",
    "cos_classifier.score(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enrollment'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(cos_classifier, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Accuracy on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.1830188679245283)\n"
     ]
    }
   ],
   "source": [
    "train_preds = train.Message.apply(lambda x : predict(cos_classifier, x))\n",
    "train_accuracy = sum(train_preds == train.Label)/float(len(train))\n",
    "print(\"Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.16777041942604856)\n"
     ]
    }
   ],
   "source": [
    "test_preds = test.Message.apply(lambda x : predict(cos_classifier, x))\n",
    "test_accuracy = sum(test_preds == test.Label)/float(len(test))\n",
    "print(\"Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Classify using Scikit-Learn Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attendance\n",
      "enrollment\n",
      "dsp\n",
      "assignments\n",
      "internal\n",
      "miscl.\n",
      "conflicts\n",
      "regrades\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "test = defaultdict(int)\n",
    "for k, v in trainclassdict.iteritems():\n",
    "    if len(v) == 0:\n",
    "        print('rip')\n",
    "    print(k)\n",
    "    for i in v:\n",
    "#         print(i)\n",
    "        test[i] += 1\n",
    "    test[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = shorttext.classifiers.TopicVectorSkLearnClassifier(topicmodeler, sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298 298 298 298 298 298 298]\n",
      " enroll ee thanks update thanks \n",
      "[ 0.37796434  0.37796434  0.37796434  0.37796525  0.37796434  0.37796434\n",
      "  0.37796434]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "classlabels = trainclassdict.keys()\n",
    "for classidx, classlabel in zip(range(len(classlabels)), classlabels):\n",
    "    topicvecs = map(topicmodeler.retrieve_topicvec, trainclassdict[classlabel])\n",
    "    if(np.any(np.isnan(topicvecs))):\n",
    "        i, _ = np.where(np.isnan(topicvecs))\n",
    "        print(i)\n",
    "        print(trainclassdict[classlabel][i[0]])\n",
    "        print(topicmodeler.retrieve_topicvec(trainclassdict[classlabel][i[0]]))\n",
    "    X += topicvecs\n",
    "    y += [classidx]*len(topicvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enroll ee thanks update thanks \n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for classidx, classlabel in zip(range(len(classlabels)), classlabels):\n",
    "    v =  trainclassdict[classlabel]\n",
    "    ct += len(v)\n",
    "    if 798 < ct:\n",
    "        print(v[798-(ct-len(v))])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n",
      "([(0, 0.14285713), (1, 0.14285721), (2, 0.14285713), (3, 0.14285715), (4, 0.14285713), (5, 0.14285713), (6, 0.14285713)], [(88, 1.0)])\n",
      "([], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n",
      "([(0, 0.14285715), (1, 0.14285715), (2, 0.14285715), (3, 0.14285715), (4, 0.14285715), (5, 0.14285715), (6, 0.14285715)], [(88, 1.0)])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(self.topicmodel[self.tfidf[bow] if self.toweigh else bow], self.tfidf[bow] if self.toweigh else bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37796447  0.37796447  0.37796447  0.37796447  0.37796447  0.37796447\n",
      "  0.37796447]\n",
      "[ nan  nan  nan  nan  nan  nan  nan]\n",
      "wtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    x  = topicmodeler.retrieve_topicvec(' discussion attendance ')\n",
    "    self = topicmodeler\n",
    "    shorttext = ' discussion attendance '\n",
    "    bow = self.retrieve_bow(shorttext)\n",
    "    topicdist = self.topicmodel[self.tfidf[bow] if self.toweigh else bow]\n",
    "#     topicdist = self.retrieve_corpus_topicdist(shorttext)\n",
    "    topicvec = np.zeros(self.nb_topics)\n",
    "    for topicid, frac in topicdist:\n",
    "        topicvec[topicid] = frac\n",
    "    if self.normalize:\n",
    "        topicvec /= np.linalg.norm(topicvec)\n",
    "    print(topicvec)\n",
    "#     print(x)\n",
    "    if np.any(np.isnan(topicvec)):\n",
    "        print('wtf')\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([704, 704, 704, 704, 704, 704, 704]), array([0, 1, 2, 3, 4, 5, 6]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(X)[np.isnan(X)]\n",
    "np.where(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[704]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e5b3670b7c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshorttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTopicVectorSkLearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopicmodeler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainclassdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/shorttext/classifiers/bow/topic/SkLearnClassification.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, classdict, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtopicvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopicvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "classifier = shorttext.classifiers.TopicVectorSkLearnClassifier(topicmodeler, sklearn_classifier)\n",
    "classifier.train(trainclassdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "classifier.score(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(classifier, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = train.Message.apply(lambda x : predict(classifier, x))\n",
    "train_accuracy = sum(train_preds == train.Label)/float(len(train))\n",
    "print(\"Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_confusion_matrix = pd.DataFrame(confusion_matrix(train.Label, train_preds, labels=categories), columns=categories, index=categories)\n",
    "train_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = test.Message.apply(lambda x : predict(classifier, x))\n",
    "test_accuracy = sum(test_preds == test.Label)/float(len(test))\n",
    "print(\"Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_confusion_matrix = pd.DataFrame(confusion_matrix(test.Label, test_preds, labels=categories), columns=categories, index=categories)\n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classify with Word2Vec model \n",
    "\n",
    "- We load the previously trained Word2Vec model by Google \n",
    "- We try a classifer that represent a text as the sum of vectors of words\n",
    "- The cos classifier compute the cosinus between the vector representing the text and the vector representing the label\n",
    "- The sklearn classifer uses the coefficients of the vector as features\n",
    "\n",
    "__Reference__: http://shorttext.readthedocs.io/en/latest/tutorial_sumvec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Load the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-3b53e059c268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwvmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_word2vec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/shorttext/utils/wordembed.pyc\u001b[0m in \u001b[0;36mload_word2vec_model\u001b[0;34m(path, binary)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1118\u001b[0m             \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joycesylo/anaconda/envs/myenv/lib/python2.7/site-packages/gensim/models/utils_any2vec.pyc\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wvmodel = load_word2vec_model('../data/GoogleNews-vectors-negative300.bin.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Classify using shorttext.classifiers.SumEmbeddedVecClassifier\n",
    "This classifier :\n",
    "- represents the text as a vector which is the sum of vectors representing words\n",
    "- compute the cosinus between this vector and the vector of the labels\n",
    "\n",
    "__Reference__: http://shorttext.readthedocs.io/en/latest/tutorial_sumvec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we should look for the file\n",
    "classifier = shorttext.classifiers.SumEmbeddedVecClassifier(wvmodel)   \n",
    "classifier.train(trainclassdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "classifier.score(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(classifier, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Accuracy on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = train.Message.apply(lambda x : predict(classifier, x))\n",
    "train_accuracy = sum(train_preds == train.Label)/float(len(train))\n",
    "print(\"Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_confusion_matrix = pd.DataFrame(confusion_matrix(train.Label, train_preds, labels=categories), columns=categories, index=categories)\n",
    "train_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = test.Message.apply(lambda x : predict(classifier, x))\n",
    "test_accuracy = sum(test_preds == test.Label)/float(len(test))\n",
    "print(\"Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_confusion_matrix = pd.DataFrame(confusion_matrix(test.Label, test_preds, labels=categories), columns=categories, index=categories)\n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Classify using a Convolutional Neural Network\n",
    "This uses convolutional Neural Network classifier built with keras.\n",
    "\n",
    "__Reference__: http://shorttext.readthedocs.io/en/latest/tutorial_nnlib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convnet classifier\n",
    "kmodel = shorttext.classifiers.frameworks.CNNWordEmbed(len(trainclassdict.keys()), vecsize=300)\n",
    "#initialize the classifier\n",
    "classifier = shorttext.classifiers.VarNNEmbeddedVecClassifier(wvmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the classifier\n",
    "classifier.train(trainclassdict, kmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.score(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Accuracy on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = train.Message.apply(lambda x : predict(classifier, x))\n",
    "train_accuracy = sum(train_preds == train.Label)/float(len(train))\n",
    "print(\"Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_confusion_matrix = pd.DataFrame(confusion_matrix(train.Label, train_preds, labels=categories), columns=categories, index=categories)\n",
    "train_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = test.Message.apply(lambda x : predict(classifier, x))\n",
    "test_accuracy = sum(test_preds == test.Label)/float(len(test))\n",
    "print(\"Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_confusion_matrix = pd.DataFrame(confusion_matrix(test.Label, test_preds, labels=categories), columns=categories, index=categories)\n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Classify using a C-LSTM Neural Network\n",
    "This uses a C-LSTM Neural Network classifier built with keras.\n",
    "\n",
    "__Reference__: http://shorttext.readthedocs.io/en/latest/tutorial_nnlib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convnet classifier\n",
    "kmodel = shorttext.classifiers.frameworks.CLSTMWordEmbed(len(trainclassdict.keys()), vecsize=300)\n",
    "#initialize the classifier\n",
    "classifier = shorttext.classifiers.VarNNEmbeddedVecClassifier(wvmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the classifier\n",
    "classifier.train(trainclassdict, kmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.score(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. Accuracy on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = train.Message.apply(lambda x : predict(classifier, x))\n",
    "train_accuracy = sum(train_preds == train.Label)/float(len(train))\n",
    "print(\"Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_confusion_matrix = pd.DataFrame(confusion_matrix(train.Label, train_preds, labels=categories), columns=categories, index=categories)\n",
    "train_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = test.Message.apply(lambda x : predict(classifier, x))\n",
    "test_accuracy = sum(test_preds == test.Label)/float(len(test))\n",
    "print(\"Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_confusion_matrix = pd.DataFrame(confusion_matrix(test.Label, test_preds, labels=categories), columns=categories, index=categories)\n",
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
